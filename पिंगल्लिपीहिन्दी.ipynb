{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738ede0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ideas import import_hook, utils\n",
    "import token_utils\n",
    "\n",
    "hi_to_py = {\n",
    "    \"असत\": \"False\",\n",
    "    \"अज्ञात\": \"None\",\n",
    "    \"सत\": \"True\",\n",
    "    \"च\": \"and\",\n",
    "    \"यथा\": \"as\",\n",
    "    \"वा\": \"assert\",\n",
    "    \"सर्ग\": \"def\",\n",
    "    \"यदि\": \"if\",\n",
    "    \"अथवा\": \"else\",    \n",
    "    \"आनय\": \"import\",      \n",
    "    \"ना\": \"not\",\n",
    "    \"या\": \"or\",  \n",
    "    \"सर्गफल\": \"return\",  \n",
    "    \"अपसरण\": \"break\",\n",
    "    \"क्रमशः\": \"for\",\n",
    "    \"में\": \"in\",\n",
    "    \"यदा\": \"while\",\n",
    "    \"क्रमश्रेणि\": \"range\",\n",
    "    \"समीकरण\": \"lambda\",\n",
    "    # अवधी : \"range\",\n",
    "    #\"अनुव्रत्ति\": \"for\",\n",
    "    #\"पुनराव्रत्ति\": \"for\",\n",
    "    # a few builtins useful for beginners    \n",
    "    #\"दर्शय\": \"print\",\n",
    "    #\"श्रेणि\": \"range\",\n",
    "    #\"async\": \"async\",  # do not translate\n",
    "    #\"await\": \"await\",  # as these are not for beginners\n",
    "    #\"is\": \"is\",    \n",
    "    #\"lambda\": \"lambda\",\n",
    "    #\"nonlocal\": \"nonlocal\",\n",
    "    #\"pass\": \"pass\",\n",
    "    #\"raise\": \"raise\",    \n",
    "    #\"from\": \"from\",\n",
    "    #\"global\": \"global\",    \n",
    "    #\"except\": \"except\",\n",
    "    #\"finally\": \"finally\",    \n",
    "    #\"del\": \"del\",\n",
    "    #\"elif\": \"elif\",    \n",
    "    #\"class\": \"class\",\n",
    "    #\"continue\": \"continue\",    \n",
    "    #\"try\": \"try\",\n",
    "    #\"while\": \"while\",\n",
    "    #\"with\": \"with\",\n",
    "    #\"yield\": \"yield\",\n",
    "    # a few builtins useful for beginners\n",
    "    #\"input\": \"input\",\n",
    "    #\"exit\": \"exit\",  # useful for console\n",
    "}\n",
    "\n",
    "hi_to_py_tokens = [tuple(([x.string for x in token_utils.tokenize(token) if x.string != ''], val)) for (token, val) in hi_to_py.items()]\n",
    "hi_to_py_first = {}\n",
    "\n",
    "for (i, (hi, py)) in enumerate(hi_to_py_tokens):\n",
    "    if hi[0] not in hi_to_py_first:\n",
    "        hi_to_py_first[hi[0]] = []\n",
    "    hi_to_py_first[hi[0]].append((len(hi), i))\n",
    "for k, v in hi_to_py_first.items():\n",
    "    v.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a17ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'असत': [(1, 0)],\n",
       " 'अज': [(5, 1)],\n",
       " 'सत': [(1, 2)],\n",
       " 'च': [(1, 3)],\n",
       " 'यथ': [(2, 4)],\n",
       " 'व': [(2, 5)],\n",
       " 'सर': [(3, 12), (3, 6)],\n",
       " 'यद': [(2, 16), (2, 7)],\n",
       " 'अथव': [(2, 8)],\n",
       " 'आनय': [(1, 9)],\n",
       " 'न': [(2, 10)],\n",
       " 'य': [(2, 11)],\n",
       " 'अपसरण': [(1, 13)],\n",
       " 'क': [(8, 17), (4, 14)],\n",
       " 'म': [(3, 15)],\n",
       " 'सम': [(3, 18)]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_to_py_tokens\n",
    "hi_to_py_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e8cf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['असत'], 'False'),\n",
       " (['अज', '्', 'ञ', 'ा', 'त'], 'None'),\n",
       " (['सत'], 'True'),\n",
       " (['च'], 'and'),\n",
       " (['यथ', 'ा'], 'as'),\n",
       " (['व', 'ा'], 'assert'),\n",
       " (['सर', '्', 'ग'], 'def'),\n",
       " (['यद', 'ि'], 'if'),\n",
       " (['अथव', 'ा'], 'else'),\n",
       " (['आनय'], 'import'),\n",
       " (['न', 'ा'], 'not'),\n",
       " (['य', 'ा'], 'or'),\n",
       " (['सर', '्', 'गफल'], 'return'),\n",
       " (['अपसरण'], 'break'),\n",
       " (['क', '्', 'रमश', 'ः'], 'for'),\n",
       " (['म', 'े', 'ं'], 'in'),\n",
       " (['यद', 'ा'], 'while'),\n",
       " (['क', '्', 'रमश', '्', 'र', 'े', 'ण', 'ि'], 'range'),\n",
       " (['सम', 'ी', 'करण'], 'lambda')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_to_py_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e895dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def untokenize(tokens): ###\n",
    "    \"\"\"\n",
    "    Converts the output of tokenize.generate_tokens back into a human-readable\n",
    "    string (that doesn't contain oddly-placed whitespace everywhere).\n",
    "\n",
    "    **Note:** Unlike tokenize.untokenize(), this function requires the 3rd and\n",
    "    4th items in each token tuple (though we can use lists *or* tuples).\n",
    "    \"\"\"\n",
    "    out = \"\"\n",
    "    last_lineno = -1\n",
    "    last_col = 0\n",
    "    for tok in tokens:\n",
    "        token_string = tok[1]\n",
    "        start_line, start_col = tok[2]\n",
    "        end_line, end_col = tok[3]\n",
    "        # The following two conditionals preserve indentation:\n",
    "        if start_line > last_lineno:\n",
    "            last_col = 0\n",
    "        if start_col > last_col:\n",
    "            out += (\" \" * (start_col - last_col))\n",
    "        out += token_string\n",
    "        last_col = end_col\n",
    "        last_lineno = end_line\n",
    "    return out\n",
    "\n",
    "import tokenize as py_tokenize\n",
    "\n",
    "def untokenize(tokens):\n",
    "    \"\"\"Return source code based on tokens.\n",
    "    Adapted from https://github.com/myint/untokenize,\n",
    "    Copyright (C) 2013-2018 Steven Myint, MIT License (same as this project).\n",
    "    This is similar to Python's own tokenize.untokenize(), except that it\n",
    "    preserves spacing between tokens, by using the line\n",
    "    information recorded by Python's tokenize.generate_tokens.\n",
    "    As a result, if the original soure code had multiple spaces between\n",
    "    some tokens or if escaped newlines were used or if tab characters\n",
    "    were present in the original source, those will also be present\n",
    "    in the source code produced by untokenize.\n",
    "    Thus ``source == untokenize(tokenize(source))``.\n",
    "    Note: if you you modifying tokens from an original source:\n",
    "    Instead of full token object, ``untokenize`` will accept simple\n",
    "    strings; however, it will only insert them *as is* without taking them\n",
    "    into account when it comes with figuring out spacing between tokens.\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    previous_line = \"\"\n",
    "    last_row = 0\n",
    "    last_column = -1\n",
    "    last_non_whitespace_token_type = None\n",
    "\n",
    "    for token in tokens:\n",
    "        if isinstance(token, str):\n",
    "            words.append(token)\n",
    "            continue\n",
    "        if token.type == py_tokenize.ENCODING:\n",
    "            continue\n",
    "\n",
    "        # Preserve escaped newlines.\n",
    "        if (\n",
    "            last_non_whitespace_token_type != py_tokenize.COMMENT\n",
    "            and token.start_row > last_row\n",
    "        ):\n",
    "            if previous_line.endswith((\"\\\\\\n\", \"\\\\\\r\\n\", \"\\\\\\r\")):\n",
    "                #pass\n",
    "                words.append(previous_line[len(previous_line.rstrip(\" \\t\\n\\r\\\\\")) :])\n",
    "\n",
    "        # Preserve spacing.\n",
    "        if token.start_row > last_row:\n",
    "            last_column = 0\n",
    "        if token.start_col > last_column:\n",
    "            whitelist = set(' \\\\\\n \\\\\\r \\\\\\r\\n')\n",
    "            line_white = ''.join(filter(whitelist.__contains__, token.line[last_column : token.start_col]))\n",
    "            words.append(line_white)\n",
    "            #words.append(token.line[last_column : token.start_col])\n",
    "\n",
    "        words.append(token.string)\n",
    "\n",
    "        previous_line = token.line\n",
    "        last_row = token.end_row\n",
    "        last_column = token.end_col\n",
    "        if not token.is_space():\n",
    "            last_non_whitespace_token_type = token.type\n",
    "\n",
    "    return \"\".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278143f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def दर्शय(*args):\n",
    "    res = []\n",
    "    for arg in args:\n",
    "        if arg == True:\n",
    "            res.append(\"सत\")\n",
    "        elif arg == False:\n",
    "            res.append(\"असत\")\n",
    "        elif arg == None:\n",
    "            res.append(\"अज्ञात\")\n",
    "        else:\n",
    "            res.append(arg)\n",
    "    print(*res)\n",
    "\n",
    "def विसत्रिताध्यास(fn, li):\n",
    "    return map(fn, li)\n",
    "    \n",
    "def match(stack, tokens):\n",
    "    #print(\"matching: \", stack, \" *** \", tokens)\n",
    "    res = False\n",
    "    for s, t in zip(stack, tokens):\n",
    "        res = True # if len > 0: res = True\n",
    "        if s.string != t: return False\n",
    "    return res\n",
    "    \n",
    "def matchIndices(stack, indices):\n",
    "    for i, index in enumerate(indices):\n",
    "        if match(stack, hi_to_py_tokens[index[1]][0]):\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def collapse(curStack, indices, new_tokens):\n",
    "    matchIndex = matchIndices(curStack, indices)\n",
    "    #print(\"eka: \", new_tokens)\n",
    "    if matchIndex == None:\n",
    "        new_tokens.extend(curStack)\n",
    "    else:\n",
    "        #for x in curStack:\n",
    "        #    x.string =\n",
    "        #for i in indices[matchIndex][0]:   \n",
    "        curStack[0].string = hi_to_py_tokens[indices[matchIndex][1]][1]\n",
    "        #curStack[0].line = hi_to_py_tokens[indices[matchIndex][1]][0][0]\n",
    "        curStack[0].end = curStack[-1].end\n",
    "        new_tokens.append(curStack[0])\n",
    "        #new_tokens.append(hi_to_py_tokens[indices[matchIndex][1]][1])\n",
    "        #print(\"dwa: \", new_tokens)\n",
    "        #print(\"putting: \", hi_to_py_tokens[indices[matchIndex][1]][1] , curStack[indices[matchIndex][0]:])\n",
    "        #print(\"info: \", indices[matchIndex][0])\n",
    "        new_tokens.extend(curStack[indices[matchIndex][0]:])\n",
    "        #print(\"trini: \", new_tokens)\n",
    "    \n",
    "def transform_source१(source, **_kwargs):\n",
    "    \"\"\"A simple replacement of 'French Python keyword' by their normal\n",
    "    English version.\n",
    "    \"\"\"\n",
    "    new_tokens = []\n",
    "    matches = []\n",
    "    curMatch = 0\n",
    "    indices = None\n",
    "    tokens = token_utils.tokenize(source)\n",
    "    #for i, x in enumerate(tokens):\n",
    "    #    print(i, tokens[i:i+1])\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        pretoken = tokens[i-1] if i > 0 else None\n",
    "        token = tokens[i]\n",
    "        if token.string in hi_to_py_first and (type(pretoken) == type(None) or pretoken.end != token.start or (pretoken.type != 1 and pretoken.type != 60)):\n",
    "            indices = hi_to_py_first[token.string]\n",
    "            maxLen = indices[0][0]\n",
    "            curMatch = min(i+maxLen, len(tokens))\n",
    "            matchIndex = matchIndices(tokens[i:curMatch], indices)\n",
    "            #print(\"checking: \", matchIndex, tokens[i:curMatch])\n",
    "            if matchIndex == None:\n",
    "                i += 1\n",
    "            else:\n",
    "                token.string = hi_to_py_tokens[indices[matchIndex][1]][1]\n",
    "                token.end = tokens[i+indices[matchIndex][0]].end\n",
    "                i += indices[matchIndex][0]\n",
    "                #print(\"adding transformed token: \", token)\n",
    "            #matchLen = collapse(tokens[i:curMatch], indices, new_tokens)\n",
    "            #print(\"ardhaadhik trini: \", token, new_tokens)\n",
    "            #val = hi_to_py_tokens[index]\n",
    "            #token.string = hi_to_py[token.string]\n",
    "        else:\n",
    "            i += 1\n",
    "            #print(\"chatwari: \", token, new_tokens)\n",
    "            #print(\"adding: \", token)\n",
    "        new_tokens.append(token)\n",
    "            #print(\"panch: \", token, new_tokens)\n",
    "    #new_source = token_utils.untokenize(new_tokens)\n",
    "    new_source = untokenize(new_tokens)\n",
    "    #print(\"final: \", new_source, new_tokens)\n",
    "    return new_source\n",
    "\n",
    "def add_hook१(**_kwargs):\n",
    "    \"\"\"Creates and adds the import hook in sys.meta_path.\n",
    "    Uses a custom extension for the exception hook.\"\"\"\n",
    "    hook = import_hook.create_hook(\n",
    "        transform_source=transform_source१,\n",
    "        hook_name='sanskrit',\n",
    "        extensions=[\".pyhi\"],\n",
    "    )\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fbbe094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VistarSyntaxError(Exception):\n",
    "    \"\"\"Currently, only raised when a repeat statement has a missing colon.\"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "def getTokensList(tokens):\n",
    "    li = []\n",
    "    for token in tokens:\n",
    "        if token.is_space() or token.is_comment():\n",
    "            continue\n",
    "        li.append(token)\n",
    "    return li\n",
    "\n",
    "def searchString(tokens, s):\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.string == s: return i\n",
    "    return None\n",
    "\n",
    "def transform_source२(source, **_kwargs):\n",
    "    token = \"क्रमशः\"\n",
    "    start = [x.string for x in token_utils.tokenize(token) if x.string != '']\n",
    "    token = \"का विस्तार\"\n",
    "    end = [x.string for x in token_utils.tokenize(token) if x.string != '']\n",
    "    new_tokens = []\n",
    "    # यदायदा क तदा ख :\n",
    "    # क का ख में विस्तार :\n",
    "    # क्रमशः क में ख का विस्तार :\n",
    "    for tokens in token_utils.get_lines(source):\n",
    "        # a line of tokens can start with INDENT or DEDENT tokens ...\n",
    "        tli= getTokensList(tokens)\n",
    "        #print(\"orig: \", tokens)\n",
    "        #ntli = []\n",
    "        if match(tli, start) and tli[4].end != tli[5].start:\n",
    "            colonIndex = searchString(tli, \":\")\n",
    "            if colonIndex == None:\n",
    "                raise VistarSyntaxError(\n",
    "                    \"विस्तार के लिये अंत में : का उपयोग करे|\"\n",
    "                    + f\"{tli[0].start_row}\\n    {tli[0].line}.\"\n",
    "                )\n",
    "            if match(reversed(tli[:colonIndex]), reversed(end)):\n",
    "                colonIndex = searchString(tokens, \":\")\n",
    "                vistarIndexRel = searchString(reversed(tokens[:colonIndex]), \"क\")\n",
    "                vistarIndex = len(tokens[:colonIndex]) - vistarIndexRel\n",
    "                #print (\"?? this: \", colonIndex, vistarIndexRel, vistarIndex)\n",
    "                tokens = tokens[:vistarIndex-1] + tokens[colonIndex:]\n",
    "            #print(\"tokens: \", tokens)\n",
    "            #print(\"joined: \", untokenize(tokens))\n",
    "            #repeat_index = token_utils.get_first_index(tokens)\n",
    "            #second_token = tokens[repeat_index + 1]\n",
    "            #first_token.string = \"for %s in %s\" % tli[1], tli[3], \n",
    "            #last_token.string = \"):\"\n",
    "        new_tokens.extend(tokens)\n",
    "    return untokenize(new_tokens)\n",
    "\n",
    "\n",
    "def add_hook२(predictable_names=False, **_kwargs):\n",
    "    \"\"\"Creates and adds the import hook in sys.meta_path.\n",
    "    If ``predictable_names`` is set to ``True``, a callback parameter\n",
    "    passed to the source transformation function will be used to\n",
    "    create variable loops with predictable names.\"\"\"\n",
    "    callback_params = {\"predictable_names\": predictable_names}\n",
    "    hook = import_hook.create_hook(\n",
    "        transform_source=transform_source२,\n",
    "        callback_params=callback_params,\n",
    "        hook_name=__name__,\n",
    "    )\n",
    "    return hook\n",
    "\n",
    "\n",
    "if __name__ != '__main__':\n",
    "    add_hook२()\n",
    "    add_hook१()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b9766ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IdeasMetaFinder object for sanskrit>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_hook२()\n",
    "add_hook१()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0c242b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "असत"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de16a5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अज्ञात\n"
     ]
    }
   ],
   "source": [
    "दर्शय(अज्ञात)\n",
    "अज्ञात"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "638b8d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "क्रमशः x में [3, 8, 1]:\n",
    "    क्रमशः y में [3, 8, 1]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da6994d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "क्रमशः y में [1,3] का विस्तार: \n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6e6ad82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':', 'र', 'ा', 'त', '्', 'स', 'ि', 'व', 'ा', 'क']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2374b7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tli = token_utils.tokenize(\"क्रमशः क में ख का विस्तार:\")\n",
    "token = \"क्रमशः\"\n",
    "start = [x.string for x in token_utils.tokenize(token) if x.string != '']\n",
    "token = \"का विस्तार:\"\n",
    "end = [x.string for x in token_utils.tokenize(token) if x.string != '']\n",
    "tli= getTokensList(tli)\n",
    "match(tli, start) and match(reversed(tli), reversed(end))\n",
    "#list(reversed(tli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38bb7e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[type=1 (NAME)  string='क'  start=(1, 0)  end=(1, 1)  line='क्रमशः क में ख का विस्तार',\n",
       " type=59 (ERRORTOKEN)  string='्'  start=(1, 1)  end=(1, 2)  line='क्रमशः क में ख का विस्तार',\n",
       " type=1 (NAME)  string='रमश'  start=(1, 2)  end=(1, 5)  line='क्रमशः क में ख का विस्तार',\n",
       " type=59 (ERRORTOKEN)  string='ः'  start=(1, 5)  end=(1, 6)  line='क्रमशः क में ख का विस्तार',\n",
       " type=1 (NAME)  string='क'  start=(1, 7)  end=(1, 8)  line='क्रमशः क में ख का विस्तार',\n",
       " type=1 (NAME)  string='म'  start=(1, 9)  end=(1, 10)  line='क्रमशः क में ख का विस्तार',\n",
       " type=59 (ERRORTOKEN)  string='े'  start=(1, 10)  end=(1, 11)  line='क्रमशः क में ख का विस्तार',\n",
       " type=59 (ERRORTOKEN)  string='ं'  start=(1, 11)  end=(1, 12)  line='क्रमशः क में ख का विस्तार',\n",
       " type=1 (NAME)  string='ख'  start=(1, 13)  end=(1, 14)  line='क्रमशः क में ख का विस्तार',\n",
       " type=1 (NAME)  string='क'  start=(1, 15)  end=(1, 16)  line='क्रमशः क में ख का विस्तार',\n",
       " type=59 (ERRORTOKEN)  string='ा'  start=(1, 16)  end=(1, 17)  line='क्रमशः क में ख का विस्तार',\n",
       " type=1 (NAME)  string='व'  start=(1, 18)  end=(1, 19)  line='क्रमशः क में ख का विस्तार',\n",
       " type=59 (ERRORTOKEN)  string='ि'  start=(1, 19)  end=(1, 20)  line='क्रमशः क में ख का विस्तार',\n",
       " type=1 (NAME)  string='स'  start=(1, 20)  end=(1, 21)  line='क्रमशः क में ख का विस्तार',\n",
       " type=59 (ERRORTOKEN)  string='्'  start=(1, 21)  end=(1, 22)  line='क्रमशः क में ख का विस्तार',\n",
       " type=1 (NAME)  string='त'  start=(1, 22)  end=(1, 23)  line='क्रमशः क में ख का विस्तार',\n",
       " type=59 (ERRORTOKEN)  string='ा'  start=(1, 23)  end=(1, 24)  line='क्रमशः क में ख का विस्तार',\n",
       " type=1 (NAME)  string='र'  start=(1, 24)  end=(1, 25)  line='क्रमशः क में ख का विस्तार',\n",
       " type=4 (NEWLINE)  string=''  start=(1, 25)  end=(1, 26)  line='',\n",
       " type=0 (ENDMARKER)  string=''  start=(2, 0)  end=(2, 0)  line='']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tli = token_utils.tokenize(\"क्रमशः क में ख का विस्तार\")\n",
    "tli\n",
    "#print(match(tli, \"क्रमशः\"))# and match(reversed(tli), reversed(\"काविस्तार:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce8b20d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['क', 'ा', 'व', 'ि', 'स', '्', 'त', 'ा', 'र', ':']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = \"का विस्तार:\"\n",
    "end = [x.string for x in token_utils.tokenize(token) if x.string != '']\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c5b0940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[type=1 (NAME)  string='क'  start=(1, 0)  end=(1, 1)  line='का विस्तार:',\n",
       " type=59 (ERRORTOKEN)  string='ा'  start=(1, 1)  end=(1, 2)  line='का विस्तार:',\n",
       " type=1 (NAME)  string='व'  start=(1, 3)  end=(1, 4)  line='का विस्तार:',\n",
       " type=59 (ERRORTOKEN)  string='ि'  start=(1, 4)  end=(1, 5)  line='का विस्तार:',\n",
       " type=1 (NAME)  string='स'  start=(1, 5)  end=(1, 6)  line='का विस्तार:',\n",
       " type=59 (ERRORTOKEN)  string='्'  start=(1, 6)  end=(1, 7)  line='का विस्तार:',\n",
       " type=1 (NAME)  string='त'  start=(1, 7)  end=(1, 8)  line='का विस्तार:',\n",
       " type=59 (ERRORTOKEN)  string='ा'  start=(1, 8)  end=(1, 9)  line='का विस्तार:',\n",
       " type=1 (NAME)  string='र'  start=(1, 9)  end=(1, 10)  line='का विस्तार:',\n",
       " type=54 (OP)  string=':'  start=(1, 10)  end=(1, 11)  line='का विस्तार:']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endt = [x for x in token_utils.tokenize(token) if x.string != '']\n",
    "#getTokensList(endt)\n",
    "print(match(endt, \"का विस्तार:\"))\n",
    "endt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d202adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[type=1 (NAME)  string='क'  start=(1, 0)  end=(1, 1)  line='क्रमश',\n",
       " type=59 (ERRORTOKEN)  string='्'  start=(1, 1)  end=(1, 2)  line='क्रमश',\n",
       " type=1 (NAME)  string='रमश'  start=(1, 2)  end=(1, 5)  line='क्रमश',\n",
       " type=4 (NEWLINE)  string=''  start=(1, 5)  end=(1, 6)  line='',\n",
       " type=0 (ENDMARKER)  string=''  start=(2, 0)  end=(2, 0)  line='']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_utils.tokenize(\"क्रमश\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b96a65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[type=1 (NAME)  string='व'  start=(1, 0)  end=(1, 1)  line='विस्तार',\n",
       " type=59 (ERRORTOKEN)  string='ि'  start=(1, 1)  end=(1, 2)  line='विस्तार',\n",
       " type=1 (NAME)  string='स'  start=(1, 2)  end=(1, 3)  line='विस्तार',\n",
       " type=59 (ERRORTOKEN)  string='्'  start=(1, 3)  end=(1, 4)  line='विस्तार',\n",
       " type=1 (NAME)  string='त'  start=(1, 4)  end=(1, 5)  line='विस्तार',\n",
       " type=59 (ERRORTOKEN)  string='ा'  start=(1, 5)  end=(1, 6)  line='विस्तार',\n",
       " type=1 (NAME)  string='र'  start=(1, 6)  end=(1, 7)  line='विस्तार',\n",
       " type=4 (NEWLINE)  string=''  start=(1, 7)  end=(1, 8)  line='',\n",
       " type=0 (ENDMARKER)  string=''  start=(2, 0)  end=(2, 0)  line='']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_utils.tokenize(\"विस्तार\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2045256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'क'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_utils.untokenize(token_utils.tokenize(\"क्रमशः क में ख का विस्तार\")[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "477c5b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=62 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line=''),\n",
       " TokenInfo(type=1 (NAME), string='अज', start=(1, 0), end=(1, 2), line='अज्ञात'),\n",
       " TokenInfo(type=59 (ERRORTOKEN), string='्', start=(1, 2), end=(1, 3), line='अज्ञात'),\n",
       " TokenInfo(type=1 (NAME), string='ञ', start=(1, 3), end=(1, 4), line='अज्ञात'),\n",
       " TokenInfo(type=59 (ERRORTOKEN), string='ा', start=(1, 4), end=(1, 5), line='अज्ञात'),\n",
       " TokenInfo(type=1 (NAME), string='त', start=(1, 5), end=(1, 6), line='अज्ञात'),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(1, 6), end=(1, 7), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(2, 0), end=(2, 0), line='')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "x = BytesIO(\"अज्ञात\".encode('utf-8')).readline\n",
    "list(py_tokenize.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16b0fc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tokenize.tokenize(readline)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_tokenize.tokenize(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55128680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=62 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line=''),\n",
       " TokenInfo(type=1 (NAME), string='अज', start=(1, 0), end=(1, 2), line='अज्ञात'),\n",
       " TokenInfo(type=59 (ERRORTOKEN), string='्', start=(1, 2), end=(1, 3), line='अज्ञात'),\n",
       " TokenInfo(type=1 (NAME), string='ञ', start=(1, 3), end=(1, 4), line='अज्ञात'),\n",
       " TokenInfo(type=59 (ERRORTOKEN), string='ा', start=(1, 4), end=(1, 5), line='अज्ञात'),\n",
       " TokenInfo(type=1 (NAME), string='त', start=(1, 5), end=(1, 6), line='अज्ञात'),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(1, 6), end=(1, 7), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(2, 0), end=(2, 0), line='')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenize import tokenize, untokenize, NUMBER, STRING, NAME, OP\n",
    "from io import BytesIO\n",
    "\n",
    "s = \"अज्ञात\"\n",
    "list(tokenize(BytesIO(s.encode()).readline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "अज्ञात"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf82d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd043ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "सर्ग fn():\n",
    "    return असत"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7df686",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [1, 3, 4]\n",
    "अमश x in li:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a32e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [1, 3, 4]\n",
    "अक्मश x in li:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [1, 4, 6]\n",
    "क्रमश x में li का विस्तार:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = ['asdf', 34]\n",
    "fot x it li:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996d9475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import token_utils\n",
    "token_utils.tokenize(\"for x in li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0595a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "दर्शय('चला', सत)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14da4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"dfas\"\n",
    "x.string = \"hi\"\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"hi\"\n",
    "y = \"hey\"\n",
    "\"for %s in %s\" % (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2738b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc3e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_utils.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c45725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
